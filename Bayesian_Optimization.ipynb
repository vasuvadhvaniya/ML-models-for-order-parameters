{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d54d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "from bayes_opt import BayesianOptimization\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import kendalltau\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import plotly.express as px\n",
    "import MDAnalysis as mda\n",
    "import scipy.io\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa73e86a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6bb182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../final_coordinates.pkl','rb') as file:\n",
    "    inp = pickle.load(file)\n",
    "with open('s_list.pkl','rb') as file:\n",
    "    s = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3281db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_distances(x):\n",
    "    square = torch.sum(x ** 2, dim=1, keepdim=True)\n",
    "    distances = square + torch.transpose(square, 0, 1) - 2 * torch.matmul(x, torch.transpose(x, 0, 1))\n",
    "    distances = torch.sqrt(distances)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d7d43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDataLoader(x, y, batch_size):\n",
    "    tensor_inp = torch.Tensor(x)\n",
    "    tensor_z = torch.Tensor(y)\n",
    "    dataset = TensorDataset(tensor_inp,tensor_z)\n",
    "    return DataLoader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cf28d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_train, inp_val, s_train, s_val = train_test_split(inp, s, test_size=0.2, random_state=69)\n",
    "inp_train, inp_test, s_train, s_test = train_test_split(inp_train, s_train, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3b5d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25782, 3072, 3) (8058, 3072, 3) (6446, 3072, 3)\n",
      "(25782, 1) (8058, 1) (6446, 1)\n"
     ]
    }
   ],
   "source": [
    "print(inp_train.shape, inp_val.shape, inp_test.shape)\n",
    "print(s_train.shape, s_val.shape, s_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99ec58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,hidden_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        self.fc3 = nn.Linear(3072,1)\n",
    "\n",
    "    def forward(self, x, adjacency_matrix):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "#         for i in range(2):\n",
    "        x = torch.matmul(adjacency_matrix, x) # Perform message passing using the adjacency matrix\n",
    "#         x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "#         x = torch.mean(x, dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3cbcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    dataset,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    length_of_set,\n",
    "    is_dev=False\n",
    "):\n",
    "    total_loss = 0\n",
    "    y_pred, y_actual = [], []\n",
    "    model.train()\n",
    "    for x,y in tqdm(dataset):\n",
    "        \n",
    "        if not is_dev: optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        num_atoms = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "        adjacency_matrix = torch.zeros(batch_size, num_atoms, num_atoms).to(device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Calculate pairwise distances between atoms\n",
    "            distances = pairwise_distances(x[i])\n",
    "            \n",
    "            # Apply threshold to set adjacency values\n",
    "            adjacency_matrix[i] = (distances < 7).float()\n",
    "        \n",
    "        pred = model(x,adjacency_matrix)\n",
    "        curr_loss = loss(pred, y)\n",
    "#         loss_batch = 0\n",
    "#         loss_batch += curr_loss.item()\n",
    "#         loss_batch = loss_batch*len(y)\n",
    "        total_loss += curr_loss.item()*len(y)/(length_of_set)\n",
    "\n",
    "        if not is_dev:\n",
    "            curr_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#         y_pred += pred\n",
    "#         y_actual += y\n",
    "        \n",
    "        y_pred += pred.flatten().tolist()\n",
    "        y_actual += y.flatten().tolist()\n",
    "    R_square = r2_score(y_actual,y_pred)\n",
    "    return total_loss,R_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a5533ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getDataLoader() missing 1 required positional argument: 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mgetDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m getDataLoader(inp_val, s_val)\n\u001b[0;32m      3\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m getDataLoader(inp_test, s_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: getDataLoader() missing 1 required positional argument: 'batch_size'"
     ]
    }
   ],
   "source": [
    "# train_dataloader = getDataLoader(inp_train, s_train)\n",
    "# val_dataloader = getDataLoader(inp_val, s_val)\n",
    "# test_dataloader = getDataLoader(inp_test, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "133c845f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_function(learning_rate, num_epochs, hidden_dim, batch_size):\n",
    "    # Define your GNN model with the given hyperparameters\n",
    "#     model = GNN(input_dim=3, hidden_dim=int(hidden_dim), output_dim=1)\n",
    "    hidden_dim = int(hidden_dim)\n",
    "    model = GNN(hidden_dim).to(device)\n",
    "    learning_rate = learning_rate\n",
    "    batch_size = int(batch_size)\n",
    "    num_epochs = int(num_epochs)\n",
    "    # Define loss and optimizer\n",
    "    loss = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_dataloader = getDataLoader(inp_train, s_train, batch_size)\n",
    "    val_dataloader = getDataLoader(inp_val, s_val, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, loss, inp_train.shape[0])\n",
    "        val_loss,val_acc = train(model, val_dataloader, optimizer, loss, inp_val.shape[0], True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, loss, inp_train.shape[0])\n",
    "        val_loss,val_acc = train(model, val_dataloader, optimizer, loss, inp_val.shape[0], True)\n",
    "        # Validation or metric evaluation\n",
    "        # Calculate validation loss or accuracy\n",
    "    \n",
    "#     train_loss,train_acc = train(model, train_dataloader, optimizer, loss, inp_train.shape[0])\n",
    "#     val_loss,val_acc = train(model, val_dataloader, optimizer, loss, inp_val.shape[0], True)\n",
    "    print(f\"Learning Rate: {learning_rate}\")\n",
    "    print(f\"Num Epochs: {num_epochs}\")\n",
    "    print(f\"Hidden Dim: {hidden_dim}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(f\"Objective Value: {val_acc}\\n\")\n",
    "\n",
    "    # Save results to a text file\n",
    "    with open('bayesian_optimization_results.txt', 'a') as file:\n",
    "        file.write(f\"Learning Rate: {learning_rate}\\n\")\n",
    "        file.write(f\"Num Epochs: {num_epochs}\\n\")\n",
    "        file.write(f\"Hidden Dim: {hidden_dim}\\n\")\n",
    "        file.write(f\"Batch Size: {batch_size}\\n\")\n",
    "        file.write(f\"Objective Value: {val_acc}\\n\\n\")\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e2a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_evaluate(model, criterion, optimizer, dataloader, num_epochs):\n",
    "#     for epoch in range(int(num_epochs)):\n",
    "#         model.train()\n",
    "#         for batch in train_dataloader:\n",
    "#             inputs, targets = batch\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         # Evaluate the model on the validation set and report metrics\n",
    "#         # You can calculate metrics like Mean Squared Error (MSE) or others\n",
    "#         validation_loss = evaluate(model, criterion, val_dataloader)\n",
    "#         print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {validation_loss:.4f}')\n",
    "#     return validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f5027e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | hidden... | learni... | num_ep... |\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▍                                                                                                         | 38/359 [15:52<2:14:06, 25.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/mtp_3.10/lib/python3.10/site-packages/bayes_opt/target_space.py:191\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: (72.0341124514471, 101.15115137044718, 0.0001001029373356104, 13.023325726318397)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m      9\u001b[0m     f\u001b[38;5;241m=\u001b[39mobjective_function,\n\u001b[1;32m     10\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39mpbounds,\n\u001b[1;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# Verbosity level\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mtp_3.10/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:305\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    303\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    304\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/.conda/envs/mtp_3.10/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:200\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/.conda/envs/mtp_3.10/lib/python3.10/site-packages/bayes_opt/target_space.py:194\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 194\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mobjective_function\u001b[0;34m(learning_rate, num_epochs, hidden_dim, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m getDataLoader(inp_val, s_val, batch_size)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     val_loss,val_acc \u001b[38;5;241m=\u001b[39m train(model, val_dataloader, optimizer, loss, inp_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Training loop\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimizer, loss, length_of_set, is_dev)\u001b[0m\n\u001b[1;32m     21\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, num_atoms, num_atoms)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Calculate pairwise distances between atoms\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Apply threshold to set adjacency values\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     adjacency_matrix[i] \u001b[38;5;241m=\u001b[39m (distances \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m7\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m square \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m distances \u001b[38;5;241m=\u001b[39m square \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(square, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(x, torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbounds = {\n",
    "    'learning_rate': (0.0001 ,0.001),\n",
    "    'num_epochs': (10, 20),\n",
    "    'hidden_dim': (32, 128),\n",
    "    'batch_size': (32,128)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=pbounds,\n",
    "    verbose=10,  # Verbosity level\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "optimizer.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc9ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
